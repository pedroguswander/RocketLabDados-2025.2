{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "663b3252-d17d-41ca-93d5-b69131f3f177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalogo = \"medalhao\"\n",
    "bronze_db_name = \"bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec00524-e01d-403d-9b51-623f0d632bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def ingest_csv(nome_arquivo, nome_tabela):\n",
    "   \n",
    "    try:\n",
    "        table_name = nome_tabela\n",
    "        landing_path = f\"/Volumes/medalhao/default/landing/{nome_arquivo}\"\n",
    "\n",
    "        # Leitura do arquivo CSV\n",
    "        df = spark.read.csv(landing_path, header=True, inferSchema=True)\n",
    "\n",
    "        # Validação: arquivo vazio\n",
    "        if df.count() == 0:\n",
    "            raise ValueError(f\"O arquivo {nome_arquivo} está vazio ou não pôde ser lido.\")\n",
    "\n",
    "        # Adiciona timestamp de ingestão\n",
    "        df_with_metadata = df.withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "\n",
    "        # Escrita no formato Delta\n",
    "        df_with_metadata.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{catalogo}.{bronze_db_name}.{table_name}\")\n",
    "\n",
    "        print(f\"✅ Tabela bronze.{nome_tabela} criada com sucesso!\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {nome_tabela}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd165b6f-e621-48a4-b66f-43b8f6a8386b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ingest_csv(\"olist_customers_dataset.csv\", \"ft_consumidores\")\n",
    "ingest_csv(\"olist_geolocation_dataset.csv\", \"ft_geolocalizacao\")\n",
    "ingest_csv(\"olist_order_items_dataset.csv\", \"ft_itens_pedidos\")\n",
    "ingest_csv(\"olist_order_payments_dataset.csv\", \"ft_pagamentos_pedidos\")\n",
    "ingest_csv(\"olist_order_reviews_dataset.csv\", \"ft_avaliacoes_pedidos\")\n",
    "ingest_csv(\"olist_orders_dataset.csv\", \"ft_pedidos\")\n",
    "ingest_csv(\"olist_products_dataset.csv\", \"ft_produtos\")\n",
    "ingest_csv(\"olist_sellers_dataset.csv\", \"ft_vendedores\")\n",
    "ingest_csv(\"product_category_name_translation.csv\", \"dm_categoria_produtos_traducao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fdeac12-c644-4d94-b193-b4ca57cc5d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "def call_api(url_param):\n",
    "    try:\n",
    "        response = requests.get(url_param, timeout=30)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53456b5-d222-4acb-b311-5876e111d922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_inicio_formatada = \"11-27-2017\"\n",
    "data_fim_formatada = \"11-28-2017\"\n",
    "\n",
    "import requests\n",
    "\n",
    "url = (\n",
    "    f\"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo\"\n",
    "    f\"(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)\"\n",
    "    f\"?@dataInicial='{data_inicio_formatada}'\"\n",
    "    f\"&@dataFinalCotacao='{data_fim_formatada}'\"\n",
    "    f\"&$select=dataHoraCotacao,cotacaoCompra&$format=json\"\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    'Cookie': 'BIGipServer~was_p_as3~was_p~pool_was_443_p=4275048876.47873.0000; JSESSIONID=0000HtHVCLHTsK-EWG0R60uBL2U:1dof89mke'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "887d2486-bfa9-4a6f-918c-79e6efd5f657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"olinda.bcb.gov.br\")\n",
    "payload = ''\n",
    "headers = {\n",
    "  'Cookie': 'BIGipServer~was_p_as3~was_p~pool_was_443_p=4275048876.47873.0000; JSESSIONID=0000uF5a70eO9nroez4e7WKOia5:1cn7jtfnj'\n",
    "}\n",
    "conn.request(\"GET\", \"/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial='11-27-2017'&@dataFinalCotacao='12-04-2017'&$top=100&$format=json&$select=cotacaoCompra,dataHoraCotacao\", payload, headers)\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6fe3cfd-1fa0-4cf0-a806-0e45c4ae0a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "df_cotacao_dolar = spark.createDataFrame([Row(data_cotacao_dolar=3.2)])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "landing_to_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
